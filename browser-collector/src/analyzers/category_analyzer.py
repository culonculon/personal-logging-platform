"""
ì¹´í…Œê³ ë¦¬ ë¶„ì„ê¸°
ì›¹ì‚¬ì´íŠ¸ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•˜ê³  ë¶„ì„í•˜ëŠ” ëª¨ë“ˆ
"""

from typing import List, Dict, Optional
from urllib.parse import urlparse
from datetime import datetime
from collections import Counter


class CategoryAnalyzer:
    """ì›¹ì‚¬ì´íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê·œì¹™ (í™•ì¥ ê°€ëŠ¥)
        self.category_patterns = {
            'social': {
                'domains': [
                    'facebook.com', 'twitter.com', 'instagram.com', 'linkedin.com',
                    'discord.com', 'reddit.com', 'youtube.com', 'tiktok.com',
                    'snapchat.com', 'pinterest.com', 'tumblr.com', 'kakao.com',
                    'band.us', 'naver.com/cafe', 'cafe.naver.com'
                ],
                'keywords': ['social', 'community', 'chat', 'message']
            },
            'work': {
                'domains': [
                    'slack.com', 'notion.so', 'trello.com', 'asana.com', 'teams.microsoft.com',
                    'zoom.us', 'meet.google.com', 'confluence.atlassian.com', 'jira.atlassian.com',
                    'monday.com', 'clickup.com', 'basecamp.com', 'office.com', 'sharepoint.com',
                    'dropbox.com', 'drive.google.com', 'onedrive.com'
                ],
                'keywords': ['work', 'office', 'team', 'project', 'meeting']
            },
            'news': {
                'domains': [
                    'naver.com', 'daum.net', 'hani.co.kr', 'chosun.com', 'joins.com',
                    'cnn.com', 'bbc.com', 'reuters.com', 'news.google.com', 'news.yahoo.com',
                    'yna.co.kr', 'sbs.co.kr', 'kbs.co.kr', 'mbc.co.kr', 'jtbc.co.kr',
                    'newspim.com', 'mt.co.kr', 'mk.co.kr'
                ],
                'keywords': ['news', 'breaking', 'report', 'article']
            },
            'entertainment': {
                'domains': [
                    'netflix.com', 'youtube.com', 'twitch.tv', 'spotify.com',
                    'disney.com', 'hulu.com', 'prime.amazon.com', 'apple.com/tv',
                    'wavve.com', 'watcha.com', 'tving.com', 'melon.com', 'genie.co.kr'
                ],
                'keywords': ['streaming', 'video', 'music', 'entertainment', 'movie']
            },
            'shopping': {
                'domains': [
                    'amazon.com', 'coupang.com', 'gmarket.co.kr', 'auction.co.kr',
                    'ebay.com', '11st.co.kr', 'interpark.com', 'yes24.com',
                    'aladin.co.kr', 'kyobobook.co.kr', 'lotte.com', 'shinsegae.com'
                ],
                'keywords': ['shop', 'buy', 'cart', 'order', 'product']
            },
            'education': {
                'domains': [
                    'coursera.org', 'udemy.com', 'khan.org', 'edx.org',
                    'stackoverflow.com', 'wikipedia.org', 'w3schools.com',
                    'codecademy.com', 'pluralsight.com', 'hackerrank.com',
                    'leetcode.com', 'programmers.co.kr', 'acmicpc.net'
                ],
                'keywords': ['learn', 'course', 'tutorial', 'education', 'study']
            },
            'developer': {
                'domains': [
                    'github.com', 'stackoverflow.com', 'medium.com', 'dev.to',
                    'docs.python.org', 'developer.mozilla.org', 'aws.amazon.com',
                    'docker.com', 'kubernetes.io', 'golang.org', 'nodejs.org',
                    'reactjs.org', 'vuejs.org', 'angular.io', 'tensorflow.org'
                ],
                'keywords': ['code', 'api', 'documentation', 'developer', 'programming']
            },
            'finance': {
                'domains': [
                    'investing.com', 'finance.yahoo.com', 'bloomberg.com',
                    'kb.co.kr', 'shinhan.com', 'wooribank.com', 'hanabank.com',
                    'nhbank.com', 'kisbank.com', 'krx.co.kr', 'naver.com/finance'
                ],
                'keywords': ['finance', 'bank', 'investment', 'stock', 'money']
            },
            'travel': {
                'domains': [
                    'booking.com', 'expedia.com', 'airbnb.com', 'agoda.com',
                    'yanolja.com', 'goodchoice.kr', 'interpark.com', 'hanatour.com',
                    'modetour.com', 'koreatravelpost.com'
                ],
                'keywords': ['travel', 'hotel', 'flight', 'booking', 'trip']
            },
            'health': {
                'domains': [
                    'webmd.com', 'mayoclinic.org', 'healthline.com',
                    'amc.seoul.kr', 'severance.or.kr', 'snuh.org', 'samsung.com/sec/medical'
                ],
                'keywords': ['health', 'medical', 'hospital', 'doctor', 'medicine']
            }
        }
        
        self.default_category = 'other'
    
    def categorize_website(self, url: str, title: str = "") -> str:
        """ë‹¨ì¼ ì›¹ì‚¬ì´íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        domain = urlparse(url).netloc.lower()
        title_lower = title.lower()
        url_lower = url.lower()
        
        for category, config in self.category_patterns.items():
            # ë„ë©”ì¸ ë§¤ì¹­
            if any(pattern in domain for pattern in config['domains']):
                return category
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ (URLê³¼ ì œëª©ì—ì„œ)
            if any(keyword in url_lower or keyword in title_lower 
                   for keyword in config['keywords']):
                return category
        
        return self.default_category
    
    def categorize_websites(self, history_data: List[Dict]) -> Dict[str, List[Dict]]:
        """ì›¹ì‚¬ì´íŠ¸ ëª©ë¡ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {category: [] for category in self.category_patterns.keys()}
        categories[self.default_category] = []
        
        for entry in history_data:
            url = entry['url']
            title = entry.get('title', '')
            
            category = self.categorize_website(url, title)
            categories[category].append(entry)
        
        return categories
    
    def analyze_category_patterns(self, categories: Dict[str, List[Dict]]) -> Dict:
        """ì¹´í…Œê³ ë¦¬ë³„ íŒ¨í„´ ë¶„ì„"""
        analysis = {}
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ í†µê³„
        category_stats = {}
        total_visits = sum(len(entries) for entries in categories.values())
        
        for category, entries in categories.items():
            if entries:
                visit_count = len(entries)
                unique_domains = len(set(entry['domain'] for entry in entries))
                
                # ì‹œê°„ëŒ€ë³„ ë¶„í¬
                hourly_dist = {}
                for entry in entries:
                    visit_time = datetime.fromisoformat(entry['visit_time'])
                    hour = visit_time.hour
                    hourly_dist[hour] = hourly_dist.get(hour, 0) + 1
                
                # ìƒìœ„ ë„ë©”ì¸
                domain_counts = Counter(entry['domain'] for entry in entries)
                top_domains = domain_counts.most_common(5)
                
                category_stats[category] = {
                    'visit_count': visit_count,
                    'percentage': round(visit_count / total_visits * 100, 1) if total_visits > 0 else 0,
                    'unique_domains': unique_domains,
                    'top_domains': top_domains,
                    'hourly_distribution': hourly_dist,
                    'peak_hour': max(hourly_dist.items(), key=lambda x: x[1])[0] if hourly_dist else None,
                    'avg_visits_per_hour': round(visit_count / len(hourly_dist), 1) if hourly_dist else 0
                }
        
        # ì „ì²´ ë¶„ì„
        analysis['category_stats'] = category_stats
        analysis['total_visits'] = total_visits
        analysis['active_categories'] = len([cat for cat, entries in categories.items() if entries])
        
        # ì£¼ìš” ì¹´í…Œê³ ë¦¬ (ë°©ë¬¸ íšŸìˆ˜ ê¸°ì¤€)
        sorted_categories = sorted(
            [(cat, stats['visit_count']) for cat, stats in category_stats.items()],
            key=lambda x: x[1], reverse=True
        )
        analysis['top_categories'] = sorted_categories[:5]
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ íŒ¨í„´
        time_patterns = {}
        for category, stats in category_stats.items():
            hourly_dist = stats['hourly_distribution']
            if hourly_dist:
                # í™œë™ ì‹œê°„ëŒ€ ë¶„ë¥˜
                morning_visits = sum(hourly_dist.get(h, 0) for h in range(6, 12))
                afternoon_visits = sum(hourly_dist.get(h, 0) for h in range(12, 18))
                evening_visits = sum(hourly_dist.get(h, 0) for h in range(18, 24))
                night_visits = sum(hourly_dist.get(h, 0) for h in range(0, 6))
                
                time_patterns[category] = {
                    'morning': morning_visits,
                    'afternoon': afternoon_visits,
                    'evening': evening_visits,
                    'night': night_visits,
                    'peak_period': max([
                        ('morning', morning_visits),
                        ('afternoon', afternoon_visits),
                        ('evening', evening_visits),
                        ('night', night_visits)
                    ], key=lambda x: x[1])[0]
                }
        
        analysis['time_patterns'] = time_patterns
        
        return analysis
    
    def get_category_insights(self, categories: Dict[str, List[Dict]]) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ ë¶„ì„ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        analysis = self.analyze_category_patterns(categories)
        insights = []
        
        if not analysis['category_stats']:
            return ["ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."]
        
        # ì „ì²´ í™œë™ ìˆ˜ì¤€
        total_visits = analysis['total_visits']
        active_categories = analysis['active_categories']
        
        insights.append(f"ì´ {total_visits}íšŒ ë°©ë¬¸, {active_categories}ê°œ ì¹´í…Œê³ ë¦¬ í™œë™")
        
        # ì£¼ìš” ì¹´í…Œê³ ë¦¬
        top_categories = analysis['top_categories']
        if top_categories:
            main_category, main_count = top_categories[0]
            percentage = round(main_count / total_visits * 100, 1)
            insights.append(f"ì£¼ìš” í™œë™ ì˜ì—­: {main_category} ({percentage}%, {main_count}íšŒ)")
        
        # ë‹¤ì–‘ì„± ë¶„ì„
        if len(top_categories) >= 3:
            top3_total = sum(count for _, count in top_categories[:3])
            diversity_ratio = top3_total / total_visits
            
            if diversity_ratio < 0.7:
                insights.append("ë§¤ìš° ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸")
            elif diversity_ratio < 0.85:
                insights.append("ì ë‹¹íˆ ë‹¤ì–‘í•œ ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš© íŒ¨í„´")
            else:
                insights.append("íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ì§‘ì¤‘ëœ ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©")
        
        # ì‹œê°„ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
        time_patterns = analysis['time_patterns']
        category_stats = analysis['category_stats']
        
        # ê° ì‹œê°„ëŒ€ë³„ ì£¼ìš” í™œë™
        period_activities = {
            'morning': [],
            'afternoon': [],
            'evening': [],
            'night': []
        }
        
        for category, pattern in time_patterns.items():
            peak_period = pattern['peak_period']
            visits = pattern[peak_period]
            if visits > 0:
                period_activities[peak_period].append((category, visits))
        
        for period, activities in period_activities.items():
            if activities:
                activities.sort(key=lambda x: x[1], reverse=True)
                main_activity = activities[0]
                period_name = {
                    'morning': 'ì˜¤ì „',
                    'afternoon': 'ì˜¤í›„', 
                    'evening': 'ì €ë…',
                    'night': 'ë°¤'
                }[period]
                insights.append(f"{period_name} ì£¼ìš” í™œë™: {main_activity[0]} ({main_activity[1]}íšŒ)")
        
        # íŠ¹ë³„í•œ íŒ¨í„´ ê°ì§€
        for category, stats in category_stats.items():
            if stats['visit_count'] > total_visits * 0.3:  # 30% ì´ìƒ
                insights.append(f"{category} ì¹´í…Œê³ ë¦¬ ì§‘ì¤‘ ì‚¬ìš© (ì „ì²´ì˜ {stats['percentage']}%)")
        
        return insights
    
    def generate_category_report(self, categories: Dict[str, List[Dict]]) -> str:
        """ì¹´í…Œê³ ë¦¬ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        analysis = self.analyze_category_patterns(categories)
        insights = self.get_category_insights(categories)
        
        report = []
        report.append("ğŸ“‚ ì›¹ì‚¬ì´íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 40)
        
        # ì „ì²´ ìš”ì•½
        report.append(f"\nğŸ“Š ì „ì²´ ìš”ì•½:")
        report.append(f"  â€¢ ì´ ë°©ë¬¸: {analysis['total_visits']}íšŒ")
        report.append(f"  â€¢ í™œì„± ì¹´í…Œê³ ë¦¬: {analysis['active_categories']}ê°œ")
        
        # ìƒìœ„ ì¹´í…Œê³ ë¦¬
        report.append(f"\nğŸ† ìƒìœ„ ì¹´í…Œê³ ë¦¬:")
        for i, (category, count) in enumerate(analysis['top_categories'], 1):
            stats = analysis['category_stats'][category]
            report.append(f"  {i}. {category}: {count}íšŒ ({stats['percentage']}%)")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸
        report.append(f"\nğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸:")
        for category, stats in analysis['category_stats'].items():
            if stats['visit_count'] > 0:
                report.append(f"\n  ğŸ”¹ {category}:")
                report.append(f"    â€¢ ë°©ë¬¸: {stats['visit_count']}íšŒ ({stats['percentage']}%)")
                report.append(f"    â€¢ ê³ ìœ  ë„ë©”ì¸: {stats['unique_domains']}ê°œ")
                if stats['peak_hour'] is not None:
                    report.append(f"    â€¢ í”¼í¬ ì‹œê°„: {stats['peak_hour']}ì‹œ")
                
                # ìƒìœ„ ë„ë©”ì¸
                if stats['top_domains']:
                    top_domain = stats['top_domains'][0]
                    report.append(f"    â€¢ ì£¼ìš” ì‚¬ì´íŠ¸: {top_domain[0]} ({top_domain[1]}íšŒ)")
        
        # ì¸ì‚¬ì´íŠ¸
        report.append(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
        for insight in insights:
            report.append(f"  â€¢ {insight}")
        
        return "\n".join(report)


def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = [
        {
            'url': 'https://github.com/user/repo',
            'title': 'GitHub Repository',
            'visit_time': '2025-08-17T10:30:00',
            'domain': 'github.com'
        },
        {
            'url': 'https://stackoverflow.com/questions/123',
            'title': 'Python question - Stack Overflow',
            'visit_time': '2025-08-17T11:15:00',
            'domain': 'stackoverflow.com'
        },
        {
            'url': 'https://youtube.com/watch?v=abc',
            'title': 'Some Video - YouTube',
            'visit_time': '2025-08-17T15:20:00',
            'domain': 'youtube.com'
        }
    ]
    
    analyzer = CategoryAnalyzer()
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    categories = analyzer.categorize_websites(test_data)
    print("ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê²°ê³¼:")
    for category, entries in categories.items():
        if entries:
            print(f"  {category}: {len(entries)}ê°œ")
    
    # ë¶„ì„ ê²°ê³¼
    analysis = analyzer.analyze_category_patterns(categories)
    print(f"\në¶„ì„ ê²°ê³¼:")
    print(f"  í™œì„± ì¹´í…Œê³ ë¦¬: {analysis['active_categories']}ê°œ")
    print(f"  ìƒìœ„ ì¹´í…Œê³ ë¦¬: {analysis['top_categories']}")
    
    # ì¸ì‚¬ì´íŠ¸
    insights = analyzer.get_category_insights(categories)
    print(f"\nì¸ì‚¬ì´íŠ¸:")
    for insight in insights:
        print(f"  â€¢ {insight}")
    
    # ë¦¬í¬íŠ¸
    print(f"\n{analyzer.generate_category_report(categories)}")


if __name__ == "__main__":
    main()
