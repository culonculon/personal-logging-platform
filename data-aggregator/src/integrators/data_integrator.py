"""
ë°ì´í„° í†µí•©ê¸° - ë¸Œë¼ìš°ì € ë° ì•± ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ í•˜ë‚˜ì˜ ì¼ì¼ í™œë™ ë¡œê·¸ ìƒì„±

Personal Logging Platform
Author: Personal Data Engineer
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import glob
from collections import defaultdict


class DataIntegrator:
    """ë¸Œë¼ìš°ì € ë°ì´í„°ì™€ ì•± ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str):
        """
        Args:
            project_root: personal-logging-platform í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
        """
        self.project_root = Path(project_root)
        self.browser_data_path = self.project_root / "browser-collector" / "output"
        self.app_data_path = self.project_root / "app-tracker" / "src" / "output"
        
    def load_browser_data(self, target_date: str = None) -> Optional[Dict]:
        """ë¸Œë¼ìš°ì € ë°ì´í„° ë¡œë“œ
        
        Args:
            target_date: YYYY-MM-DD í˜•ì‹. Noneì´ë©´ ê°€ì¥ ìµœì‹  ë°ì´í„°
            
        Returns:
            í†µí•©ëœ ë¸Œë¼ìš°ì € ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            if target_date:
                # íŠ¹ì • ë‚ ì§œ ë°ì´í„° ì°¾ê¸°
                summary_pattern = f"browser_summary_{target_date.replace('-', '')}.json"
                complete_pattern = f"browser_complete_{target_date.replace('-', '')}_*.json"
            else:
                # ìµœì‹  ë°ì´í„° ì°¾ê¸°
                summary_files = list(self.browser_data_path.glob("browser_summary_*.json"))
                if not summary_files:
                    print("âš ï¸  ë¸Œë¼ìš°ì € ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return None
                
                latest_summary = max(summary_files, key=os.path.getctime)
                date_str = latest_summary.stem.split('_')[-1]  # 20250817
                summary_pattern = f"browser_summary_{date_str}.json"
                complete_pattern = f"browser_complete_{date_str}_*.json"
            
            # Summary ë°ì´í„° ë¡œë“œ
            summary_files = list(self.browser_data_path.glob(summary_pattern))
            complete_files = list(self.browser_data_path.glob(complete_pattern))
            
            if not summary_files:
                print(f"âš ï¸  {target_date or 'ìµœì‹ '} ë‚ ì§œì˜ ë¸Œë¼ìš°ì € ìš”ì•½ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
            with open(summary_files[0], 'r', encoding='utf-8') as f:
                summary_data = json.load(f)
                
            # Complete ë°ì´í„° ë¡œë“œ (ìˆìœ¼ë©´)
            complete_data = None
            if complete_files:
                with open(complete_files[0], 'r', encoding='utf-8') as f:
                    complete_data = json.load(f)
            
            return {
                'type': 'browser',
                'date': summary_data.get('date'),
                'summary': summary_data,
                'complete': complete_data,
                'source_files': {
                    'summary': str(summary_files[0]),
                    'complete': str(complete_files[0]) if complete_files else None
                }
            }
            
        except Exception as e:
            print(f"âŒ ë¸Œë¼ìš°ì € ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_app_data(self, target_date: str = None) -> Optional[Dict]:
        """ì•± ë°ì´í„° ë¡œë“œ
        
        Args:
            target_date: YYYY-MM-DD í˜•ì‹. Noneì´ë©´ ê°€ì¥ ìµœì‹  ë°ì´í„°
            
        Returns:
            í†µí•©ëœ ì•± ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not self.app_data_path.exists():
                print("âš ï¸  ì•± ì¶”ì  ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì•± ì¶”ì ê¸°ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return None
                
            if target_date:
                # íŠ¹ì • ë‚ ì§œ ë°ì´í„° ì°¾ê¸°
                summary_pattern = f"app_summary_{target_date.replace('-', '')}.json"
                complete_pattern = f"app_complete_{target_date.replace('-', '')}_*.json"
            else:
                # ìµœì‹  ë°ì´í„° ì°¾ê¸°
                summary_files = list(self.app_data_path.glob("app_summary_*.json"))
                if not summary_files:
                    print("âš ï¸  ì•± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì•± ì¶”ì ê¸°ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    return None
                
                latest_summary = max(summary_files, key=os.path.getctime)
                date_str = latest_summary.stem.split('_')[-1]
                summary_pattern = f"app_summary_{date_str}.json"
                complete_pattern = f"app_complete_{date_str}_*.json"
            
            # Summary ë°ì´í„° ë¡œë“œ
            summary_files = list(self.app_data_path.glob(summary_pattern))
            complete_files = list(self.app_data_path.glob(complete_pattern))
            
            if not summary_files:
                print(f"âš ï¸  {target_date or 'ìµœì‹ '} ë‚ ì§œì˜ ì•± ìš”ì•½ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
            with open(summary_files[0], 'r', encoding='utf-8') as f:
                summary_data = json.load(f)
                
            # Complete ë°ì´í„° ë¡œë“œ (ìˆìœ¼ë©´)
            complete_data = None
            if complete_files:
                with open(complete_files[0], 'r', encoding='utf-8') as f:
                    complete_data = json.load(f)
            
            return {
                'type': 'app',
                'date': summary_data.get('date'),
                'summary': summary_data,
                'complete': complete_data,
                'source_files': {
                    'summary': str(summary_files[0]),
                    'complete': str(complete_files[0]) if complete_files else None
                }
            }
            
        except Exception as e:
            print(f"âŒ ì•± ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def integrate_daily_data(self, target_date: str = None) -> Dict:
        """ì¼ì¼ ë°ì´í„° í†µí•©
        
        Args:
            target_date: YYYY-MM-DD í˜•ì‹. Noneì´ë©´ ê°€ì¥ ìµœì‹  ë°ì´í„°
            
        Returns:
            í†µí•©ëœ ì¼ì¼ í™œë™ ë°ì´í„°
        """
        print(f"ğŸ”„ ì¼ì¼ ë°ì´í„° í†µí•© ì‹œì‘...")
        
        # ë°ì´í„° ë¡œë“œ
        browser_data = self.load_browser_data(target_date)
        app_data = self.load_app_data(target_date)
        
        # ë‚ ì§œ ê²°ì •
        if browser_data and app_data:
            integration_date = browser_data['date'] or app_data['date']
        elif browser_data:
            integration_date = browser_data['date']
        elif app_data:
            integration_date = app_data['date']
        else:
            integration_date = target_date or datetime.now().strftime('%Y-%m-%d')
        
        integrated_data = {
            'date': integration_date,
            'timestamp': datetime.now().isoformat(),
            'data_sources': {
                'browser': browser_data is not None,
                'app': app_data is not None
            },
            'browser_data': browser_data,
            'app_data': app_data
        }
        
        # í†µí•© ë¶„ì„ ìˆ˜í–‰
        integrated_data['analysis'] = self._perform_integration_analysis(browser_data, app_data)
        
        print(f"âœ… ë°ì´í„° í†µí•© ì™„ë£Œ: {integration_date}")
        print(f"   - ë¸Œë¼ìš°ì € ë°ì´í„°: {'âœ“' if browser_data else 'âœ—'}")
        print(f"   - ì•± ë°ì´í„°: {'âœ“' if app_data else 'âœ—'}")
        
        return integrated_data
    
    def _perform_integration_analysis(self, browser_data: Optional[Dict], app_data: Optional[Dict]) -> Dict:
        """ë¸Œë¼ìš°ì €ì™€ ì•± ë°ì´í„°ì˜ êµì°¨ ë¶„ì„"""
        analysis = {
            'activity_overview': {},
            'productivity_insights': {},
            'time_patterns': {},
            'focus_analysis': {},
            'category_breakdown': {},
            'recommendations': []
        }
        
        try:
            # í™œë™ ê°œìš” ìƒì„±
            total_browser_visits = browser_data['summary']['summary']['total_visits'] if browser_data else 0
            total_app_sessions = len(app_data['complete']['sessions']) if app_data and app_data['complete'] else 0
            
            analysis['activity_overview'] = {
                'total_browser_visits': total_browser_visits,
                'total_app_sessions': total_app_sessions,
                'data_richness': 'high' if browser_data and app_data else 'medium'
            }
            
            # ìƒì‚°ì„± ë¶„ì„
            if browser_data and app_data:
                browser_dev_ratio = 0
                if browser_data['summary']['highlights']['top_categories']:
                    for cat, count in browser_data['summary']['highlights']['top_categories']:
                        if cat in ['developer', 'work', 'education']:
                            browser_dev_ratio += count / total_browser_visits
                
                analysis['productivity_insights'] = {
                    'browser_productivity_ratio': round(browser_dev_ratio, 3),
                    'main_focus_areas': self._extract_focus_areas(browser_data, app_data),
                    'productivity_score': self._calculate_productivity_score(browser_data, app_data)
                }
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ì„
            if browser_data:
                analysis['category_breakdown'] = {
                    'browser_categories': browser_data['summary']['highlights']['top_categories'][:5],
                    'top_domains': browser_data['summary']['highlights']['top_domains'][:5]
                }
                
            # ì‹œê°„ íŒ¨í„´ ë¶„ì„
            if browser_data:
                peak_hour = browser_data['summary']['highlights']['peak_hour']
                analysis['time_patterns'] = {
                    'browser_peak_hour': peak_hour,
                    'activity_distribution': f"ë¸Œë¼ìš°ì € í™œë™ í”¼í¬: {peak_hour}ì‹œ"
                }
            
            # ì¶”ì²œì‚¬í•­ ìƒì„±
            analysis['recommendations'] = self._generate_recommendations(browser_data, app_data)
            
        except Exception as e:
            print(f"âš ï¸  í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            analysis['error'] = str(e)
        
        return analysis
    
    def _extract_focus_areas(self, browser_data: Dict, app_data: Dict) -> List[str]:
        """ì£¼ìš” ì§‘ì¤‘ ì˜ì—­ ì¶”ì¶œ"""
        focus_areas = []
        
        if browser_data:
            top_categories = browser_data['summary']['highlights']['top_categories']
            for cat, _ in top_categories[:3]:
                if cat == 'developer':
                    focus_areas.append('ê°œë°œ')
                elif cat == 'education':
                    focus_areas.append('í•™ìŠµ')
                elif cat == 'work':
                    focus_areas.append('ì—…ë¬´')
                else:
                    focus_areas.append(cat)
        
        return focus_areas
    
    def _calculate_productivity_score(self, browser_data: Dict, app_data: Dict) -> int:
        """ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚° (0-100)"""
        score = 50  # ê¸°ë³¸ ì ìˆ˜
        
        if browser_data:
            # ê°œë°œ/ì—…ë¬´/êµìœ¡ ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ë¡œ ì ìˆ˜ ì¡°ì •
            total_visits = browser_data['summary']['summary']['total_visits']
            productive_visits = 0
            
            for cat, count in browser_data['summary']['highlights']['top_categories']:
                if cat in ['developer', 'work', 'education']:
                    productive_visits += count
            
            productivity_ratio = productive_visits / total_visits if total_visits > 0 else 0
            score += int(productivity_ratio * 40)  # ìµœëŒ€ 40ì  ì¶”ê°€
        
        return min(100, max(0, score))
    
    def _generate_recommendations(self, browser_data: Dict, app_data: Dict) -> List[str]:
        """ê°œì¸í™”ëœ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if browser_data:
            # ë¸Œë¼ìš°ì € íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ
            peak_hour = browser_data['summary']['highlights']['peak_hour']
            
            if peak_hour < 6:  # ìƒˆë²½ ì‹œê°„ í™œë™
                recommendations.append("ìƒˆë²½ ì‹œê°„ëŒ€ í™œë™ì´ ë§ìŠµë‹ˆë‹¤. ì¶©ë¶„í•œ ìˆ˜ë©´ì„ ìœ„í•´ ì·¨ì¹¨ ì‹œê°„ì„ ì•ë‹¹ê¸°ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
            
            # ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ì²´í¬
            categories = len(browser_data['summary']['highlights']['top_categories'])
            if categories < 3:
                recommendations.append("ì›¹ í™œë™ì´ íŠ¹ì • ì˜ì—­ì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì»¨í…ì¸ ë„ íƒìƒ‰í•´ë³´ì„¸ìš”.")
            
            # ê²€ìƒ‰ í™œë™ ë¶„ì„
            search_count = browser_data['summary']['summary']['search_count']
            if search_count > 20:
                recommendations.append("ê²€ìƒ‰ í™œë™ì´ í™œë°œí•©ë‹ˆë‹¤. ì°¾ì€ ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ë‚˜ì¤‘ì— ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ ë¬¸ì„œí™”í•´ë³´ì„¸ìš”.")
        
        if not browser_data and not app_data:
            recommendations.append("ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•´ë³´ì„¸ìš”. ë” ì •í™•í•œ ë¶„ì„ê³¼ ì¶”ì²œì„ ìœ„í•´ì„œëŠ” ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return recommendations
    
    def save_integrated_data(self, integrated_data: Dict, output_path: str = None) -> str:
        """í†µí•© ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if output_path is None:
            date_str = integrated_data['date'].replace('-', '')
            timestamp = datetime.now().strftime('%H%M%S')
            filename = f"integrated_data_{date_str}_{timestamp}.json"
            output_path = self.project_root / "data-aggregator" / "output" / filename
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(integrated_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ í†µí•© ë°ì´í„° ì €ì¥ë¨: {output_path}")
        return str(output_path)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    sys.path.append(str(Path(__file__).parent.parent.parent))
    
    project_root = "/Users/admin/Documents/GitHub/personal-logging-platform"
    integrator = DataIntegrator(project_root)
    
    # ë°ì´í„° í†µí•© ì‹¤í–‰
    integrated_data = integrator.integrate_daily_data()
    
    # ê²°ê³¼ ì €ì¥
    output_file = integrator.save_integrated_data(integrated_data)
    
    print(f"\nğŸ¯ ë°ì´í„° í†µí•© ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_file}")
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {integrated_data['analysis']['activity_overview']}")
